{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ml as pdml\n",
    "import pyodbc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest, BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, average_precision_score, recall_score \n",
    "from sklearn.metrics import auc, precision_score, confusion_matrix, f1_score, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect(DSN='BGI40PROD')\n",
    "\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"select\tCONSTITUENTSYSTEMID\n",
    "        ,CONSTITUENTLOOKUPID\n",
    "\t\t,SORTNAMESHORT\n",
    "\t\t,CONSTITUENTAGE\n",
    "from uif.v_DIM_CONSTITUENT\n",
    "where ISINDIVIDUAL = 1 and ISDECEASED = 0 and ISACTIVE = 1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfmsql = \"\"\"select\trfm.CONSTITUENTSYSTEMID\n",
    "\t\t,rfm.DAYSDIFF\n",
    "\t\t,PERCENT_RANK () over (order by rfm.DAYSDIFF desc) as r_percentile\n",
    "\t\t,rfm.count_gifts\n",
    "\t\t,PERCENT_RANK () over (order by rfm.count_gifts asc) as f_percentile\n",
    "\t\t,rfm.total_giving\n",
    "\t\t,PERCENT_RANK () over (order by rfm.total_giving asc) as m_percentile\n",
    "\t\t,[RFM] = PERCENT_RANK () over (order by rfm.total_giving asc)  + PERCENT_RANK () over (order by rfm.count_gifts asc) + PERCENT_RANK () over (order by rfm.DAYSDIFF desc)\n",
    "\t\t\n",
    "from\n",
    "\n",
    "(select distinct a.CONSTITUENTSYSTEMID\n",
    "\t\t,convert(date,a.TargetDate) as TargetDate\n",
    "\t\t,DATEDIFF(dd,g.last_gift_date,a.TargetDate) as DAYSDIFF\n",
    "\t\t,isnull(g.count_gifts,0) as count_gifts\n",
    "\t\t,convert(date,g.last_gift_date) as RecentGiftDate\n",
    "\t\t,isnull(g.total_giving,0) as total_giving\n",
    "from\n",
    "(select CONSTITUENTSYSTEMID\n",
    "\t\t,convert(date,min(ORIGINALGIFTDATE)) as TargetDate\n",
    "from [UIF].[v_DIM_PLANNEDGIFT]\n",
    "where STATUS <> 'Withdrawn'\n",
    "group by CONSTITUENTSYSTEMID\n",
    "\n",
    "union\n",
    "\n",
    "select CONSTITUENTSYSTEMID\n",
    "\t\t,convert(date,GETDATE()) as TargetDate\n",
    "from uif.v_DIM_CONSTITUENT\n",
    "where isindividual = 1 and isactive = 1) a\n",
    "\n",
    "join (\n",
    "\n",
    "select\tdonor_id\n",
    "\t\t,count_gifts\n",
    "\t\t,last_gift_date\n",
    "\t\t,total_giving\n",
    "\n",
    "from\n",
    "(\n",
    "\tselect\ta.[Recognized ConstituentSystemID] as donor_id\n",
    "\t\t\t,count(a.RevenueLookupID) as count_gifts\n",
    "\t\t\t,max(a.RevenueDate) as last_gift_date\n",
    "\t\t\t,sum(a.RecognitionAmount) as total_giving\n",
    "\n",
    "\t\tfrom [UIF].[GIVING_DETAIL_RECOGNITION] a\n",
    "\t\tjoin pm.v_DateAttributes da on a.RevenueDateDimID = da.DATEDIMID\n",
    "\t\twhere\t(a.RecognitionAmount > 0\n",
    "\t\t\t\tand a.REVENUERECOGNITIONTYPE in ('Primary','Shared','Prior Household Joint')\n",
    "\t\t\t\tand a.REVENUETRANSACTIONTYPE = 'Payment'\n",
    "\t\t\t\tand a.REVENUEAPPLICATION in ('Recurring Gift', 'Membership','Matching gift','Pledge')\n",
    "\t\t\t\tor (a.REVENUERECOGNITIONTYPE in ('Primary','Shared','Prior Household Joint')\n",
    "\t\t\t\t\tand a.RevenueTransactionType = 'Payment'\n",
    "\t\t\t\t\tand a.RevenueApplication = 'Donation'\n",
    "\t\t\t\t\tand a.CampusGiftType = 'Gift'\n",
    "\t\t\t\t\tand a.RecognitionAmount > 0))\n",
    "\t\t\t\tand exists (select a.*\n",
    "\t\t\t\t\t\t\tfrom (select distinct v.CONSTITUENTSYSTEMID as systemid\n",
    "\t\t\t\t\t\t\t\tfrom [VM].[v_Fact_DegreeArea] b\n",
    "\t\t\t\t\t\t\t\tjoin uif.v_DIM_CONSTITUENT v on b.ConstituentDimID = v.CONSTITUENTDIMID\n",
    "\t\t\t\t\t\t\t\tjoin [VM].[v_Dim_DegreeArea] c ON b.DegreeAreaDIMID = c.DegreeAreaDIMID\n",
    "\t\t\t\t\t\t\t\twhere c.DegreeArea ='Law Grads'\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\tunion\n",
    "\n",
    "\t\t\t\t\t\t\t\tselect distinct q.ID as systemid\n",
    "\t\t\t\t\t\t\t\tfrom [dbo].[ADHOCQUERY_STATICIDSET_D9DB4F82_8EE5_4CC2_B35D_66A6BD369A38] q\n",
    "\t\t\t\t\t\t\t\tjoin uif.v_DIM_CONSTITUENT b on q.ID = b.CONSTITUENTSYSTEMID\n",
    "\t\t\t\t\t\t\t\twhere b.ISINDIVIDUAL = 1 and b.ISACTIVE = 1) w where w.systemid = a.[Recognized ConstituentSystemID])\n",
    "\tgroup by a.[Recognized ConstituentSystemID]) a ) g on a.CONSTITUENTSYSTEMID = g.donor_id\n",
    "\n",
    "\twhere exists (select a.*\n",
    "\t\t\t\t\t\t\tfrom (select distinct v.CONSTITUENTSYSTEMID as systemid\n",
    "\t\t\t\t\t\t\t\tfrom [VM].[v_Fact_DegreeArea] b\n",
    "\t\t\t\t\t\t\t\tjoin uif.v_DIM_CONSTITUENT v on b.ConstituentDimID = v.CONSTITUENTDIMID\n",
    "\t\t\t\t\t\t\t\tjoin [VM].[v_Dim_DegreeArea] c ON b.DegreeAreaDIMID = c.DegreeAreaDIMID\n",
    "\t\t\t\t\t\t\t\twhere c.DegreeArea ='Law Grads'\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\tunion\n",
    "\n",
    "\t\t\t\t\t\t\t\tselect distinct q.ID as systemid\n",
    "\t\t\t\t\t\t\t\tfrom [dbo].[ADHOCQUERY_STATICIDSET_D9DB4F82_8EE5_4CC2_B35D_66A6BD369A38] q\n",
    "\t\t\t\t\t\t\t\tjoin uif.v_DIM_CONSTITUENT b on q.ID = b.CONSTITUENTSYSTEMID\n",
    "\t\t\t\t\t\t\t\twhere b.ISINDIVIDUAL = 1 and b.ISACTIVE = 1) w where w.systemid = a.CONSTITUENTSYSTEMID)\n",
    "\t\t\tand (g.donor_id is null or g.last_gift_date < a.TargetDate) ) rfm\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app = pd.read_sql(sql, con=cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = pd.read_sql(rfmsql, con=cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = rfm.sort_values('RFM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['Rank_Pct']= rfm.RFM.rank(pct=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = rfm.sort_values('Rank_Pct', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfm.to_csv(\"C:/Users/palmberg/Documents/GitHub/LawAFMAP/Data/rfm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas_ml confusion matrix: http://pandas-ml.readthedocs.io/en/latest/conf_mat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"//uiffs01/dataanalytics/LawAffinityPG/lawdata_new1.csv\")\n",
    "\n",
    "df.fillna(0, inplace=True)  # we should do a better job of cleaning than this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set a random seed variable\n",
    "seed = 11251442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to create column of bin values from big measures\n",
    "# https://community.modeanalytics.com/python/tutorial/defining-python-functions/\n",
    "def amount_bin (value):\n",
    "    if value == 0 :\n",
    "        return 'nonDonor'\n",
    "    elif 0 < value < 100 :\n",
    "        return 'donor_<100'\n",
    "    elif 100 <= value < 250 :\n",
    "        return 'donor_100-249'\n",
    "    elif 250 <= value < 500 :\n",
    "        return 'donor_250-499'\n",
    "    elif 500 <= value < 1000 :\n",
    "        return 'donor_500-999'\n",
    "    elif 1000 <= value < 5000 :\n",
    "        return 'donor_1000-4999'\n",
    "    elif 5000 <= value < 10000 :\n",
    "        return 'donor_5000-9999'\n",
    "    elif 10000 <= value < 25000 :\n",
    "        return 'donor_10000-24999'\n",
    "    elif 25000 <= value < 50000 :\n",
    "        return 'donor_25000-49999'\n",
    "    return 'donor_>50000'\n",
    "\n",
    "# helper function to create column of bin values from smaller measures\n",
    "def count_bin (value):\n",
    "    if value == 0 :\n",
    "        return 'nonDonor'\n",
    "    elif 0 < value < 9 :\n",
    "        return '<10'\n",
    "    elif 10 <= value < 20 :\n",
    "        return '10-19'\n",
    "    elif 20 <= value < 30 :\n",
    "        return '20-29'\n",
    "    elif 30 <= value < 40 :\n",
    "        return '20-39'\n",
    "    elif 40 <= value < 50 :\n",
    "        return '40-49'\n",
    "    elif 50 <= value < 60 :\n",
    "        return '50-59'\n",
    "    elif 60 <= value < 70 :\n",
    "        return '60-69'\n",
    "    elif 70 <= value < 80 :\n",
    "        return '70-79'\n",
    "    return '>80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function to bin RFM rank into quintiles, lumping 0s into the bottom \"quintile\"\n",
    "def rank_bin (value):\n",
    "    if  0 <= value < 20 :\n",
    "        return '20th'\n",
    "    elif 20 <= value < 40 :\n",
    "        return '40th'\n",
    "    elif 40 <= value < 60 :\n",
    "        return '60th'\n",
    "    elif 60 <= value < 80 :\n",
    "        return '80th'\n",
    "    return '100th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create new categorical fields using the helper functions\n",
    "df['LWG_SUM_PRIOR_PG_BIN'] = df['LWG_SUM_BEFORE_PG'].apply(amount_bin)\n",
    "\n",
    "df['NON_LWG_SUM_PRIOR_PG_BIN'] = df['NON_LWG_SUM_BEFORE_PG'].apply(amount_bin)\n",
    "\n",
    "df['NON_LWG_GIFTYEARSCOUNT_PRIOR_PG_BIN'] = df['NON_LWG_GIFTYEARSCOUNT_PRIOR_PG'].apply(count_bin)\n",
    "\n",
    "df['LWG_GIFTYEARSCOUNT_BEFORE_PG_BIN'] = df['LWG_GIFTYEARSCOUNT_BEFORE_PG'].apply(count_bin)\n",
    "\n",
    "df['LWG_CONSECUTIVE_PRIOR_PG_BIN'] = df['LWG_CONSECUTIVE_PRIOR_PG'].apply(count_bin)\n",
    "\n",
    "df['NON_LWG_CONSECUTIVE_PRIOR_PG_BIN'] = df['NON_LWG_CONSECUTIVE_PRIOR_PG'].apply(count_bin)\n",
    "\n",
    "df['PRE_PG_YEARS_WITH_CONTACT_REPORT_BIN'] = df['PRE_PG_YEARS_WITH_CONTACT_REPORT'].apply(count_bin)\n",
    "\n",
    "df['NON_LWG_CONSECUTIVE_PRIOR_PG_BIN'] = df['NON_LWG_CONSECUTIVE_PRIOR_PG'].apply(count_bin)\n",
    "\n",
    "df['LWG_CONSECUTIVE_PRIOR_PG_BIN'] = df['LWG_CONSECUTIVE_PRIOR_PG'].apply(count_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#just checking a couple of the new features\n",
    "df[['CONSTITUENTSYSTEMID','LWG_SUM_BEFORE_PG','LWG_SUM_PRIOR_PG_BIN', 'NON_LWG_SUM_BEFORE_PG', /\n",
    "    'NON_LWG_SUM_PRIOR_PG_BIN']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#produce bar graph of one of the features created above to check distributions\n",
    "df['LWG_GIFTYEARSCOUNT_BEFORE_PG_BIN'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new column for Law giving as a % of total giving\n",
    "df['LWG%'] = (df['LWG_SUM_BEFORE_PG'] / (df['LWG_SUM_BEFORE_PG'] + df['NON_LWG_SUM_BEFORE_PG'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new column to indicate donors who've made more than 50% of their donations to Law\n",
    "df['LWG>50%'] = (df['LWG_OVER_50%'] > 50.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new column to indicate donors who've *only* given to Law\n",
    "df['LWG_ONLY_DONOR'] = (df['LWG_OVER_50%'] == 100.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['MLTPL_RESIDENCE_EVER'] = (df['RESIDENCE_COUNT_EVER'] > 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['MLTPL_INVOLVEMENT'] = (df['INVOLVEMENT_COUNT'] > 1).astype(int)\n",
    "\n",
    "df['MLTPL_INVOLVEMENT_TYPE'] = (df['INVOLVEMENT_TYPE_COUNT'] > 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get dummies for all the categorical features I just made\n",
    "pd.get_dummies(data=df, columns=['LWG_CONSECUTIVE_PRIOR_PG_BIN', 'NON_LWG_CONSECUTIVE_PRIOR_PG_BIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop the original measures used to create the categorical variables, as well as ID, dependent variable, and others\n",
    "cols1 = df.drop(['CONSTITUENTSYSTEMID', 'HAS_PLANNED_GIFT', 'HAS_EMAIL', 'ISDECEASED', 'LWG_SUM_BEFORE_PG', 'NON_LWG_SUM_BEFORE_PG', 'PRE_PG_YEARS_WITH_CONTACT_REPORT', 'INVOLVEMENT_COUNT', 'INVOLVEMENT_TYPE_COUNT', 'RESIDENCE_COUNT_EVER', 'LWG_CONSECUTIVE_PRIOR_PG', 'NON_LWG_CONSECUTIVE_PRIOR_PG', 'LWG%'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#see which columns are of type 'object' so I can apply dummy encoding\n",
    "list(cols1.select_dtypes(include='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define X and y as dependent and independent variables\n",
    "X = cols1\n",
    "y = df.HAS_PLANNED_GIFT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tuning Random Forest Models](https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modified this to replace the random_state value with the pre-defined seed variable\n",
    "print(\"X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, bootstrap=True, n_jobs=-1, random_state=seed, class_weight=\"balanced_subsample\")\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = SelectFromModel(clf, threshold=\".5*mean\", prefit=True)\n",
    "X_train2 = selector.transform(X_train)\n",
    "X_test2 = selector.transform(X_test)\n",
    "print(\"X_train2:\", X_train2.shape)\n",
    "print(\"X_test2:\", X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col_index(df):\n",
    "    return {i: list(df.columns)[i] for i in range(len(df.columns))}\n",
    "\n",
    "ind = col_index(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = X_train2.shape[1]\n",
    "\n",
    "features = list(ind.values())\n",
    "importances = clf.feature_importances_\n",
    "indices = list(np.argsort(importances))[-n:]\n",
    "\n",
    "plt.figure(figsize=(8,26))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), [importances[i] for i in indices], color='#FFCD00', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices]) \n",
    "plt.xlabel('Relative Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top = [ind[i] for i in indices[-n:]]\n",
    "\n",
    "top.reverse()\n",
    "\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify the model params/values here for testing\n",
    "\n",
    "rf = RandomForestClassifier(oob_score = True, n_jobs = -1,random_state =seed, max_features = \"auto\", class_weight=\"balanced_subsample\")\n",
    "\n",
    "param_grid = {\"n_estimators\": [1000, 1500, 2000],\n",
    "              \"max_depth\": [None]\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(rf, param_grid=param_grid, scoring = 'average_precision', n_jobs=-1)\n",
    "\n",
    "model = gs.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_rf = model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_rf = model.best_estimator_\n",
    "\n",
    "final_rf.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, final_rf.predict_proba(X_train2)[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "Fpr, Tpr, Thresholds = roc_curve(y_test, final_rf.predict_proba(X_test2)[:, 1])\n",
    "Roc_auc = auc(Fpr, Tpr)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='Train ROC (area = %0.2f)' % roc_auc)\n",
    "plt.plot(fpr, thresholds, color='darkorange', linestyle='-.')\n",
    "plt.plot(Fpr, Tpr, color='gray',\n",
    "         lw=lw, label='Test ROC (area = %0.2f)' % Roc_auc)\n",
    "plt.plot(Fpr, Thresholds, color='gray', linestyle='-.', lw=3)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc.png')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = X_train2.shape[1]\n",
    "\n",
    "features = list(ind.values())\n",
    "importances = clf.feature_importances_\n",
    "indices = list(np.argsort(importances))[-n:]\n",
    "\n",
    "plt.figure(figsize=(8,26))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), [importances[i] for i in indices], color='#FFCD00', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices]) \n",
    "plt.xlabel('Relative Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(final_rf.predict_proba(X_test2)[:, 1], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, final_rf.predict_proba(X_train2)[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "Fpr, Tpr, Thresholds = roc_curve(y_test, final_rf.predict_proba(X_test2)[:, 1])\n",
    "Roc_auc = auc(Fpr, Tpr)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='Train ROC (area = %0.2f)' % roc_auc)\n",
    "plt.plot(fpr, thresholds, color='darkorange', linestyle='-.')\n",
    "plt.plot(Fpr, Tpr, color='gray',\n",
    "         lw=lw, label='Test ROC (area = %0.2f)' % Roc_auc)\n",
    "plt.plot(Fpr, Thresholds, color='gray', linestyle='-.', lw=3)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc.png')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nope = X[y == 0]\n",
    "\n",
    "X2 = selector.transform(nope)\n",
    "\n",
    "#col = ['ConstituentID', 'ConstituentAge', \"SCORE\"] +  cols\n",
    "\n",
    "nope = nope.assign(SCORE = (final_rf.predict_proba(X2)[:,1]))\n",
    "\n",
    "#nope.loc[:, col].sort_values(by=\"SCORE\", ascending=False).head(50)\n",
    "\n",
    "nope.sort_values(by=\"SCORE\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set series to_frame to enable merge\n",
    "\n",
    "nope = pd.merge(nope, df.loc[df.ISDECEASED==0,\"CONSTITUENTSYSTEMID\"].to_frame(), how=\"inner\", left_index=True, right_index=True )\n",
    "nope.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nope.sort_values(by=\"SCORE\", ascending=False).head(100).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shouldn't need this anymore, as transformed these features to categorical and then dummies\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "nope.loc[:, ['LWG_GIFTYEARSCOUNT_BEFORE_PG',\n",
    "          'RESIDENCE_COUNT_EVER',\n",
    "          'LWG_CONSECUTIVE_PRIOR_PG',\n",
    "          'NON_LWG_CONSECUTIVE_PRIOR_PG',\n",
    "          'NON_LWG_GIFTYEARSCOUNT_PRIOR_PG',\n",
    "          'LWG_SUM_BEFORE_PG',\n",
    "          'NON_LWG_SUM_BEFORE_PG',\n",
    "          'PRE_PG_YEARS_WITH_CONTACT_REPORT',\n",
    "          'INVOLVEMENT_COUNT',\n",
    "          'INVOLVEMENT_TYPE_COUNT']] = \\\n",
    "scaler.inverse_transform(nope.loc[:, ['LWG_GIFTYEARSCOUNT_BEFORE_PG',\n",
    "          'RESIDENCE_COUNT_EVER',\n",
    "          'LWG_CONSECUTIVE_PRIOR_PG',\n",
    "          'NON_LWG_CONSECUTIVE_PRIOR_PG',\n",
    "          'NON_LWG_GIFTYEARSCOUNT_PRIOR_PG',\n",
    "          'LWG_SUM_BEFORE_PG',\n",
    "          'NON_LWG_SUM_BEFORE_PG',\n",
    "          'PRE_PG_YEARS_WITH_CONTACT_REPORT',\n",
    "          'INVOLVEMENT_COUNT',\n",
    "          'INVOLVEMENT_TYPE_COUNT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nope = pd.merge(nope, app, how='inner', on='CONSTITUENTSYSTEMID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nope.sort_values(by=\"SCORE\", ascending=False).head(100).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create objects to use to create a confusion matrix\n",
    "# y_test = y_true y_pred = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a function to indicate whether column 1 in pred is > .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold (predict):\n",
    "    if predict >= .5 :\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for i in range(pred.shape[0]):\n",
    "    if pred[i, 1] >= .5:\n",
    "        d.append((i, 0, pred[i, 1]))\n",
    "    else:\n",
    "        d.append((i,0,pred[i, 1]))\n",
    "d[:10]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.vectorize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.apply_along_axis(threshold, 1, pred[:,1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred[:, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred[:, 1].reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred[:, 1].reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = np.vectorize(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh(pred[:, 1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,thresh(pred[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
